# Google Cloud Storage (`gcs`)

Write events to a Google Cloud bucket.


## Contents

- [Fields](#fields)




## Fields


| Field | Type | Required | Description |
|---|---|:---:|---|
| `retry` | [`Retry`](#retry-fields) |  | How to retry operation if it fails. |
| `batch` | [`Batch`](#batch-fields) |  | How to collect input events into batches. |
| `input-field` | `event-field` (`string`) |  | Use the specified field as the content for the file line. |
| `bucket-name` | `string` | ✅ | Bucket Name. |
| `object-name` | `gcs_output:object-name` | ✅ | Remote Object name, may include slashes. |
| `disable-object-name-guid` | `boolean` (`bool`) |  | Disable the GUID prefix if you want object name to be treated literally (off for deletes). |
| `guid-prefix` | `string` |  | GUID Prefix, will be prepended to the GUID, the default value is "/". |
| `guid-suffix` | `string` |  | GUID Suffix, will be appended to the GUID if specified. |
| `credentials` | `gcs_output:credentials` | ✅ | Credentials for GCP. |
| `mode` | [`Mode`](#mode-options) |  | Put or delete the object? Default is Put. |
| `preprocessors` | [`Preprocessors`](#preprocessors-options) |  | Preprocessors (process data before making it available for upload) these processors will be run in the order they are specified. |
| `track-schema` | `boolean` (`bool`) |  | Check the schema of the written data and update __SCHEMA_NUMBER (written data must be JSON). |





<h3 id="retry-fields">Retry Fields</h3>

| Field | Type | Required | Description |
|---|---|:---:|---|
| `count` | [`integer`](../types/retry-count.md#retry-count) | ❌ | How to retry? Either forever or for a limited number of times. |
| `pause` | [`string`](../types/retry-pause.md#retry-pause) | ❌ | How long to pause before re-trying. |



<h3 id="batch-fields">Batch Fields</h3>

| Field | Type | Required | Description |
|---|---|:---:|---|
| `fixed-size` | [`integer`](../types/batch-out-fixed-size.md#batch-out-fixed-size) | ❌ | maximum number of events in an output batch. |
| `mode` | [`symbol`](../types/batch-out-mode.md#batch-out-mode) | ✅ | If 'document' send on end of document generated by input. If 'fixed', use `fixed_size`. |
| `timeout` | [`string`](../types/batch-out-timeout.md#batch-out-timeout) | ✅ | interval after which the batch is sent, to keep throughput going (default 100ms). |
| `header` | [`string`](../types/batch-out-header.md#batch-out-header) | ❌ | put a header line before the batch. |
| `footer` | [`string`](../types/batch-out-footer.md#batch-out-footer) | ❌ | put a header line after the last line of the batch. |
| `use-document-marker` | [`bool`](../types/batch-out-use-document-marker.md#batch-out-use-document-marker) | ❌ | Enrich the job metadata with a document marker (for document handling in batch mode). |
| `wrap-as-json` | [`bool`](../types/batch-out-wrap-as-json.md#batch-out-wrap-as-json) | ❌ | Format the output batch as a JSON array. |





<h3 id="mode-options">Mode Options</h3>

| Value | Name | Description |
|---|---|---|
| `put` | put | Put Objects |
| `delete` | delete | Delete Objects |



<h3 id="preprocessors-options">Preprocessors Options</h3>

| Value | Name | Description |
|---|---|---|
| `gzip` | gzip | Gzip the output data |
| `parquet` | parquet | Extract the received data as JSON rows from a parquet file |
| `base64` | base64 | Decode base64 as binary |




---
Prev: [File Store](file-store.md)  
Next: [HTTP Get](http-get.md)  
